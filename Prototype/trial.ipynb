{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6676654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd054f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39097ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello there! I'm not Charlie, but I'm happy to chat with you! Is there something I can help you with or would you like to just have a conversation?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 13, 'total_tokens': 49, 'completion_time': 0.064833201, 'prompt_time': 0.010173493, 'queue_time': 0.271673424, 'total_time': 0.075006694}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_bf16903a67', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--625decb8-8708-4183-a1a1-7eea3291f7b9-0', usage_metadata={'input_tokens': 13, 'output_tokens': 36, 'total_tokens': 49})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello charlie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755687a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "\n",
    "#Reason of creating this state is that we will let this value goes through all node and get updated.\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Have the user input which will be later passed to llm model for output generation.\n",
    "\n",
    "    Attributes:\n",
    "        name: Name of the candidate\n",
    "        email: Email of the candidate\n",
    "        phone_number: Phone number of the candidate\n",
    "        years_of_experience: Years of experience of the candidate\n",
    "        desired_position: Desired position of the candidate\n",
    "        current_location: Current location of the candidate\n",
    "        tech_stack: Tech stack of the candidate\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    email: str\n",
    "    phone_number: str\n",
    "    years_of_experience: int\n",
    "    desired_position: str\n",
    "    current_location: str\n",
    "    tech_stack: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "576d620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a senior technical interviewer with 15 years of experience in {tech_stack}. \n",
    "You are the tech lead of the company.\n",
    "\n",
    "Your task is to ask the candidate 3–6 **relevant and non-repetitive** technical questions \n",
    "based on their provided tech stack, years of experience, and the {desired_position} role.\n",
    "\n",
    "- Cover programming languages, frameworks, databases, and tools from their {tech_stack}.\n",
    "- Tailor questions to their {years_of_experience} years of experience level.\n",
    "- If a listed tech stack is irrelevant to the {desired_position}, do not ask questions about it. \n",
    "  Instead, politely inform the candidate that those skills are not relevant for this role.\n",
    "\n",
    "After asking the questions, gracefully conclude by thanking the candidate \n",
    "and informing them about the next steps.\n",
    "\n",
    "Format:\n",
    "Hello {name},\n",
    "\n",
    "Question 1: ...\n",
    "Question 2: ...\n",
    "Question 3: ...\n",
    "(optional more up to 6)\n",
    "\n",
    "Thank you for your time, {name}. Our team will review your responses and get back to you with the next steps.\n",
    "\"\"\",\n",
    "    input_variables=[\"tech_stack\", \"years_of_experience\", \"desired_position\", \"name\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0adc88b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Abhishek,\n",
      "\n",
      "I'll be asking you a series of technical questions to assess your skills and experience as a Backend Developer with Python and Django. Please feel free to ask for clarification if needed.\n",
      "\n",
      "Question 1: In Django, how would you optimize the performance of a view that retrieves a large dataset from the database? What strategies would you use to reduce the load on the database and improve the response time?\n",
      "\n",
      "Question 2: Suppose you have a Django model with a many-to-many field. How would you implement a custom manager to filter the related objects based on a specific condition? Can you provide an example of how you would use this custom manager in a view?\n",
      "\n",
      "Question 3: When using Django's ORM, how do you handle database transactions to ensure data consistency and integrity? Can you explain the difference between atomicity and consistency in the context of database transactions?\n",
      "\n",
      "Question 4: How would you implement authentication and authorization in a Django RESTful API using token-based authentication? What are some best practices to follow when implementing authentication and authorization in a Django project?\n",
      "\n",
      "Question 5: Suppose you need to integrate a third-party API into your Django project. How would you handle errors and exceptions when making API calls to the third-party service? Can you explain how you would implement retry mechanisms and logging to handle errors effectively?\n",
      "\n",
      "Thank you for your time, Abhishek. Our team will review your responses and get back to you with the next steps.\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(prompt=prompt_template, llm=llm)\n",
    "\n",
    "# Run the chain with candidate details\n",
    "response = chain.run({\n",
    "    \"tech_stack\": \"Python, Django\",\n",
    "    \"years_of_experience\": 3,\n",
    "    \"desired_position\": \"Backend Developer\",\n",
    "    \"name\": \"Abhishek\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4a8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Candidate inserted successfully!\n",
      "{'_id': ObjectId('68b1c8146085456147063178'), 'name': 'Test User', 'email': 'test@example.com', 'phone_number': '+91-1234567890', 'years_of_experience': 2, 'desired_position': 'Backend Developer', 'current_location': 'Delhi, India', 'tech_stack': ['Python', 'FastAPI', 'PostgreSQL']}\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Fixed connection string (password '@' → '%40')\n",
    "uri = \"\"\n",
    "\n",
    "# Connect to MongoDB Atlas\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# Create or connect to database\n",
    "db = client[\"hiring_assistant\"]\n",
    "\n",
    "# Create or connect to collection\n",
    "candidates = db[\"candidate_info\"]\n",
    "\n",
    "# Candidate example\n",
    "candidate = {\n",
    "    \"name\": \"Test User\",\n",
    "    \"email\": \"test@example.com\",\n",
    "    \"phone_number\": \"+91-1234567890\",\n",
    "    \"years_of_experience\": 2,\n",
    "    \"desired_position\": \"Backend Developer\",\n",
    "    \"current_location\": \"Delhi, India\",\n",
    "    \"tech_stack\": [\"Python\", \"FastAPI\", \"PostgreSQL\"]\n",
    "}\n",
    "\n",
    "# Insert candidate\n",
    "candidates.insert_one(candidate)\n",
    "print(\"✅ Candidate inserted successfully!\")\n",
    "\n",
    "# Fetch candidates\n",
    "for cand in candidates.find():\n",
    "    print(cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e81e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates.find_one({\"name\": \"Abhishek\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
